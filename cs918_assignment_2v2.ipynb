{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Two:  Sentiment Classification\n",
    "\n",
    "For this exercise you will be using the \"SemEval 2017 task 4\" corpus provided on the module website, available through the following link: https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs918/semeval-tweets.tar.bz2 You will focus particularly on Subtask A, i.e. classifying the overall sentiment of a tweet as positive, negative or neutral.\n",
    "\n",
    "You are requested to produce a Jupyter notebook for the coursework submission. The input to your program is the SemEval data downloaded. Note that TAs need to run your program on their own machine by using the original SemEval data. As such, donâ€™t submit a Python program that takes as input some preprocessed files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary packages\n",
    "You may import more packages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import re\n",
    "from os.path import join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton: Evaluation code for the test sets\n",
    "def read_test(testset):\n",
    "    '''\n",
    "    readin the testset and return a dictionary\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    '''\n",
    "    id_gts = {}\n",
    "    with open(testset, 'r', encoding='utf8') as fh:\n",
    "        for line in fh:\n",
    "            fields = line.split('\\t')\n",
    "            tweetid = fields[0]\n",
    "            gt = fields[1]\n",
    "\n",
    "            id_gts[tweetid] = gt\n",
    "\n",
    "    return id_gts\n",
    "\n",
    "\n",
    "def confusion(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the confusion matrix of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    gts = []\n",
    "    for m, c1 in id_gts.items():\n",
    "        if c1 not in gts:\n",
    "            gts.append(c1)\n",
    "\n",
    "    gts = ['positive', 'negative', 'neutral']\n",
    "\n",
    "    conf = {}\n",
    "    for c1 in gts:\n",
    "        conf[c1] = {}\n",
    "        for c2 in gts:\n",
    "            conf[c1][c2] = 0\n",
    "\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "        conf[pred][gt] += 1\n",
    "\n",
    "    print(''.ljust(12) + '  '.join(gts))\n",
    "\n",
    "    for c1 in gts:\n",
    "        print(c1.ljust(12), end='')\n",
    "        for c2 in gts:\n",
    "            if sum(conf[c1].values()) > 0:\n",
    "                print('%.3f     ' % (conf[c1][c2] / float(sum(conf[c1].values()))), end='')\n",
    "            else:\n",
    "                print('0.000     ', end='')\n",
    "        print('')\n",
    "\n",
    "    print('')\n",
    "\n",
    "\n",
    "def evaluate(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the macro-F1 score of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    acc_by_class = {}\n",
    "    for gt in ['positive', 'negative', 'neutral']:\n",
    "        acc_by_class[gt] = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
    "\n",
    "    catf1s = {}\n",
    "\n",
    "    ok = 0\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "\n",
    "        if gt == pred:\n",
    "            ok += 1\n",
    "            acc_by_class[gt]['tp'] += 1\n",
    "        else:\n",
    "            acc_by_class[gt]['fn'] += 1\n",
    "            acc_by_class[pred]['fp'] += 1\n",
    "\n",
    "    catcount = 0\n",
    "    itemcount = 0\n",
    "    macro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    micro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    semevalmacro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "\n",
    "    microtp = 0\n",
    "    microfp = 0\n",
    "    microtn = 0\n",
    "    microfn = 0\n",
    "    for cat, acc in acc_by_class.items():\n",
    "        catcount += 1\n",
    "\n",
    "        microtp += acc['tp']\n",
    "        microfp += acc['fp']\n",
    "        microtn += acc['tn']\n",
    "        microfn += acc['fn']\n",
    "\n",
    "        p = 0\n",
    "        if (acc['tp'] + acc['fp']) > 0:\n",
    "            p = float(acc['tp']) / (acc['tp'] + acc['fp'])\n",
    "\n",
    "        r = 0\n",
    "        if (acc['tp'] + acc['fn']) > 0:\n",
    "            r = float(acc['tp']) / (acc['tp'] + acc['fn'])\n",
    "\n",
    "        f1 = 0\n",
    "        if (p + r) > 0:\n",
    "            f1 = 2 * p * r / (p + r)\n",
    "\n",
    "        catf1s[cat] = f1\n",
    "\n",
    "        n = acc['tp'] + acc['fn']\n",
    "\n",
    "        macro['p'] += p\n",
    "        macro['r'] += r\n",
    "        macro['f1'] += f1\n",
    "\n",
    "        if cat in ['positive', 'negative']:\n",
    "            semevalmacro['p'] += p\n",
    "            semevalmacro['r'] += r\n",
    "            semevalmacro['f1'] += f1\n",
    "\n",
    "        itemcount += n\n",
    "\n",
    "    micro['p'] = float(microtp) / float(microtp + microfp)\n",
    "    micro['r'] = float(microtp) / float(microtp + microfn)\n",
    "    micro['f1'] = 2 * float(micro['p']) * micro['r'] / float(micro['p'] + micro['r'])\n",
    "\n",
    "    semevalmacrof1 = semevalmacro['f1'] / 2\n",
    "\n",
    "    print(testset + ' (' + classifier + '): %.3f' % semevalmacrof1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load training set, dev set and testing set\n",
    "Here, you need to load the training set, the development set and the test set. For better classification results, you may need to preprocess tweets before sending them to the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Piotrek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Piotrek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Piotrek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Piotrek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('wordnet')\n",
    "#!pip install contractions\n",
    "import contractions\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "all_stopwords=stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "\n",
    "# Load training set, dev set and testing set\n",
    "data = {}\n",
    "tweetids = {}\n",
    "tweetgts = {}\n",
    "tweets = {}\n",
    "\n",
    "\n",
    "for dataset in ['twitter-training-data.txt'] + testsets + ['twitter-dev-data.txt']:\n",
    "    data[dataset] = []\n",
    "    tweets[dataset] = []\n",
    "    tweetids[dataset] = []\n",
    "    tweetgts[dataset] = []\n",
    "\n",
    "    # write code to read in the datasets here\n",
    "    with open(dataset,'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('\\t')\n",
    "            #lowercase\n",
    "            fields[2]=fields[2].lower()\n",
    "            #remove newlines\n",
    "            fields[2]=re.sub(r\"\\n\",\"\", fields[2])\n",
    "            #remove url and www\n",
    "            fields[2]=re.sub(r\"(http|ftp|www)\\S+\",\"\",fields[2])\n",
    "            #remove the user mentions (@) and hashtags (#)\n",
    "            fields[2]=re.sub(r\"([@#] ?)\\S+\",\"\",fields[2])\n",
    "            words_lem=[]\n",
    "            #split line into words\n",
    "            words_=fields[2].split()\n",
    "            #use contractions (convert \"shouldn't\" to \"should not\")\n",
    "            expanded_words=[]\n",
    "            for word_ in words_:\n",
    "                expanded_words.append(contractions.fix(word_)) \n",
    "            #remove stop words\n",
    "            words_no_stop = [word for word in expanded_words if not word in all_stopwords]\n",
    "            #use pos tagging to lemmatize the words\n",
    "            words_pos_tag=nltk.pos_tag(words_no_stop, tagset = \"universal\")\n",
    "            for i1 in range(len(words_no_stop)):\n",
    "                type1=words_pos_tag[i1][1]\n",
    "                if type1==\"VERB\":\n",
    "                    type2=nltk.corpus.wordnet.VERB\n",
    "                elif type1==\"ADJ\":\n",
    "                    type2=nltk.corpus.wordnet.ADJ\n",
    "                elif type1==\"ADV\":\n",
    "                    type2=nltk.corpus.wordnet.ADV\n",
    "                else:\n",
    "                    type2=nltk.corpus.wordnet.NOUN\n",
    "                words_lem.append(lemmatizer.lemmatize(words_pos_tag[i1][0],type2))\n",
    "            new_fields2 =' '.join(words_lem)\n",
    "            fields[2]=new_fields2\n",
    "            #remove non alpha-numeric characters\n",
    "            #fields[2]=re.sub(r\"[^A-Za-z0-9 ]\", \"\",fields[2])\n",
    "            #remove all words starting with a number/digit\n",
    "            fields[2]=re.sub(r\"\\b[0-9]\\S*\", \"\",fields[2])\n",
    "            #remove all one letter characters \n",
    "            fields[2]=re.sub(r\"\\b[a-z]\\b\", \"\",fields[2])\n",
    "            #assign fields accordingly  \n",
    "            tweetid = fields[0]\n",
    "            gt = fields[1]\n",
    "            tweet = fields[2]\n",
    "            data[dataset].append(fields)\n",
    "            tweets[dataset].append(tweet)\n",
    "            tweetids[dataset].append(tweetid)\n",
    "            tweetgts[dataset].append(gt)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build sentiment classifiers\n",
    "You need to create your own classifiers (at least 3 classifiers). For each classifier, you can choose between the bag-of-word features and the word-embedding-based features. Each classifier has to be evaluated over 3 test sets. Make sure your classifier produce consistent performance across the test sets. Marking will be based on the performance over all 5 test sets (2 of them are not provided to you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'semeval-tweets\\\\twitter-test1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b8a33ec60efd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mtestset_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mtestset_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'semeval-tweets'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-cfd7c1e7799d>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(id_preds, testset, classifier)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     '''\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mid_gts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0macc_by_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-cfd7c1e7799d>\u001b[0m in \u001b[0;36mread_test\u001b[1;34m(testset)\u001b[0m\n\u001b[0;32m      6\u001b[0m     '''\n\u001b[0;32m      7\u001b[0m     \u001b[0mid_gts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'semeval-tweets\\\\twitter-test1.txt'"
     ]
    }
   ],
   "source": [
    "# Buid traditional sentiment classifiers. An example classifier name 'svm' is given\n",
    "# in the code below. You should replace the other two classifier names\n",
    "# with your own choices. For features used for classifier training, \n",
    "# the 'bow' feature is given in the code. But you could also explore the \n",
    "# use of other features.\n",
    "for classifier in ['svc', 'NB', 'NB_tfidf']:\n",
    "    for features in ['bow']:\n",
    "        # Skeleton: Creation and training of the classifiers\n",
    "        if classifier == 'svm':\n",
    "            # write the svm classifier here\n",
    "            print('Training ' + classifier)\n",
    "        elif classifier == '<classifier-2-name>':\n",
    "            # write the classifier 2 here\n",
    "            print('Training ' + classifier)\n",
    "        elif classifier == '<classifier-3-name>':\n",
    "            # write the classifier 3 here\n",
    "            print('Training ' + classifier)\n",
    "        elif classifier == 'LSTM':\n",
    "            # write the LSTM classifier here\n",
    "            if features == 'bow':\n",
    "                continue\n",
    "            print('Training ' + classifier)\n",
    "        else:\n",
    "            print('Unknown classifier name' + classifier)\n",
    "            continue\n",
    "\n",
    "        # Predition performance of the classifiers\n",
    "        for testset in testsets:\n",
    "            id_preds = {}\n",
    "            # write the prediction and evaluation code here\n",
    "\n",
    "            testset_name = testset\n",
    "            testset_path = join('semeval-tweets', testset_name)\n",
    "            evaluate(id_preds, testset_path, features + '-' + classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(tweets['twitter-training-data.txt'])\n",
    "# TfidfTransformer transoforms count matrix to tf-idf representation.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# fit_transform transforms count matrix to tf-idf representation(vector).\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_test1=vectorizer.transform(tweets['twitter-test1.txt'])\n",
    "X_test2=vectorizer.transform(tweets['twitter-test2.txt'])\n",
    "X_test3=vectorizer.transform(tweets['twitter-test3.txt'])\n",
    "X_test_tfidf1=tfidf_transformer.transform(X_test1)\n",
    "X_test_tfidf2=tfidf_transformer.transform(X_test2)\n",
    "X_test_tfidf3=tfidf_transformer.transform(X_test3)\n",
    "Y_train=tweetgts['twitter-training-data.txt']\n",
    "Y_test1=tweetgts['twitter-test1.txt']\n",
    "Y_test2=tweetgts['twitter-test2.txt']\n",
    "Y_test3=tweetgts['twitter-test3.txt']\n",
    "X_valid=vectorizer.transform(tweets['twitter-dev-data.txt'])\n",
    "Y_valid=tweetgts['twitter-dev-data.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-test1.txt (NB): 0.512\n",
      "twitter-test2.txt (NB): 0.475\n",
      "twitter-test3.txt (NB): 0.476\n",
      "            positive  negative  neutral\n",
      "positive    0.610     0.081     0.309     \n",
      "negative    0.114     0.692     0.194     \n",
      "neutral     0.264     0.166     0.570     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.675     0.074     0.251     \n",
      "negative    0.217     0.478     0.304     \n",
      "neutral     0.338     0.127     0.536     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.631     0.088     0.281     \n",
      "negative    0.223     0.466     0.311     \n",
      "neutral     0.296     0.157     0.547     \n",
      "\n",
      "twitter-test1.txt (NB_tfidf): 0.380\n",
      "twitter-test2.txt (NB_tfidf): 0.402\n",
      "twitter-test3.txt (NB_tfidf): 0.369\n",
      "            positive  negative  neutral\n",
      "positive    0.615     0.088     0.297     \n",
      "negative    0.025     0.825     0.150     \n",
      "neutral     0.249     0.205     0.546     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.681     0.076     0.243     \n",
      "negative    0.125     0.625     0.250     \n",
      "neutral     0.325     0.145     0.531     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.632     0.107     0.261     \n",
      "negative    0.319     0.511     0.170     \n",
      "neutral     0.290     0.174     0.536     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training the NB model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "NB = naive_bayes.MultinomialNB()\n",
    "NB.fit(X_train,Y_train)\n",
    "#generate predictions for NB model\n",
    "predictions_NB1 = NB.predict(X_test1)\n",
    "predictions_NB2 = NB.predict(X_test2)\n",
    "predictions_NB3 = NB.predict(X_test3)\n",
    "#train NB model with tf-idf as model inputs \n",
    "NB.fit(X_train_tfidf,Y_train)\n",
    "#generate predictions for NB model with tf-idf as model inputs\n",
    "predictions_NB1_tfidf = NB.predict(X_test1)\n",
    "predictions_NB2_tfidf = NB.predict(X_test2)\n",
    "predictions_NB3_tfidf = NB.predict(X_test3)\n",
    "\n",
    "#create dictionaries with the predictions\n",
    "predictions_NB1_dict=dict(zip(tweetids['twitter-test1.txt'],predictions_NB1))\n",
    "predictions_NB2_dict=dict(zip(tweetids['twitter-test2.txt'],predictions_NB2))\n",
    "predictions_NB3_dict=dict(zip(tweetids['twitter-test3.txt'],predictions_NB3))\n",
    "predictions_NB1_tfidf_dict=dict(zip(tweetids['twitter-test1.txt'],predictions_NB1_tfidf))\n",
    "predictions_NB2_tfidf_dict=dict(zip(tweetids['twitter-test2.txt'],predictions_NB2_tfidf))\n",
    "predictions_NB3_tfidf_dict=dict(zip(tweetids['twitter-test3.txt'],predictions_NB3_tfidf))\n",
    "#evaluate the performance of the classifier\n",
    "eval1=evaluate(predictions_NB1_dict,'twitter-test1.txt','NB')\n",
    "eval2=evaluate(predictions_NB2_dict,'twitter-test2.txt','NB')\n",
    "eval3=evaluate(predictions_NB3_dict,'twitter-test3.txt','NB')\n",
    "\n",
    "#generate confusion matrices\n",
    "conf1=confusion(predictions_NB1_dict,'twitter-test1.txt','NB')\n",
    "conf2=confusion(predictions_NB2_dict,'twitter-test2.txt','NB')\n",
    "conf3=confusion(predictions_NB3_dict,'twitter-test3.txt','NB')\n",
    "\n",
    "#do the same for tf-idf\n",
    "\n",
    "eval1=evaluate(predictions_NB1_tfidf_dict,'twitter-test1.txt','NB_tfidf')\n",
    "eval2=evaluate(predictions_NB2_tfidf_dict,'twitter-test2.txt','NB_tfidf')\n",
    "eval3=evaluate(predictions_NB3_tfidf_dict,'twitter-test3.txt','NB_tfidf')\n",
    "\n",
    "conf1=confusion(predictions_NB1_tfidf_dict,'twitter-test1.txt','NB_tfidf')\n",
    "conf2=confusion(predictions_NB2_tfidf_dict,'twitter-test2.txt','NB_tfidf')\n",
    "conf3=confusion(predictions_NB3_tfidf_dict,'twitter-test3.txt','NB_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-test1.txt (svc): 0.543\n",
      "twitter-test2.txt (svc): 0.555\n",
      "twitter-test3.txt (svc): 0.476\n",
      "            positive  negative  neutral\n",
      "positive    0.785     0.054     0.161     \n",
      "negative    0.112     0.807     0.081     \n",
      "neutral     0.267     0.151     0.583     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.810     0.056     0.134     \n",
      "negative    0.104     0.806     0.090     \n",
      "neutral     0.349     0.103     0.548     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.763     0.079     0.157     \n",
      "negative    0.211     0.648     0.141     \n",
      "neutral     0.306     0.144     0.549     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#train the model\n",
    "svc = OneVsRestClassifier(SVC()).fit(X_train, Y_train)\n",
    "#generate predictions \n",
    "predictions_svc1=svc.predict(X_test1)\n",
    "predictions_svc2=svc.predict(X_test2)\n",
    "predictions_svc3=svc.predict(X_test3)\n",
    "#create the dictionary with the predictions\n",
    "predictions_svc1_dict=dict(zip(tweetids['twitter-test1.txt'],predictions_svc1))\n",
    "predictions_svc2_dict=dict(zip(tweetids['twitter-test2.txt'],predictions_svc2))\n",
    "predictions_svc3_dict=dict(zip(tweetids['twitter-test3.txt'],predictions_svc3))\n",
    "#evaluate the perfomance\n",
    "eval_svc1=evaluate(predictions_svc1_dict,'twitter-test1.txt','svc')\n",
    "eval_svc2=evaluate(predictions_svc2_dict,'twitter-test2.txt','svc')\n",
    "eval_svc3=evaluate(predictions_svc3_dict,'twitter-test3.txt','svc')\n",
    "#generate confusion matrices\n",
    "conf_svc1=confusion(predictions_svc1_dict,'twitter-test1.txt','svc')\n",
    "conf_svc2=confusion(predictions_svc2_dict,'twitter-test2.txt','svc')\n",
    "conf_svc3=confusion(predictions_svc3_dict,'twitter-test3.txt','svc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-test1.txt (log_reg): 0.559\n",
      "twitter-test2.txt (log_reg): 0.571\n",
      "twitter-test3.txt (log_reg): 0.536\n",
      "            positive  negative  neutral\n",
      "positive    0.691     0.060     0.249     \n",
      "negative    0.158     0.653     0.189     \n",
      "neutral     0.276     0.142     0.583     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.736     0.049     0.215     \n",
      "negative    0.178     0.645     0.178     \n",
      "neutral     0.364     0.104     0.532     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.711     0.066     0.223     \n",
      "negative    0.205     0.545     0.250     \n",
      "neutral     0.301     0.134     0.565     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#train the model\n",
    "log_reg=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "log_reg.fit(X_train,Y_train)\n",
    "#generate predictions\n",
    "predictions_log_reg1 = log_reg.predict(X_test1)\n",
    "predictions_log_reg2 = log_reg.predict(X_test2)\n",
    "predictions_log_reg3 = log_reg.predict(X_test3)\n",
    "#create dictionaries with the predictions\n",
    "predictions_log_reg1_dict=dict(zip(tweetids['twitter-test1.txt'],predictions_log_reg1))\n",
    "predictions_log_reg2_dict=dict(zip(tweetids['twitter-test2.txt'],predictions_log_reg2))\n",
    "predictions_log_reg3_dict=dict(zip(tweetids['twitter-test3.txt'],predictions_log_reg3))\n",
    "#evaluate the performance\n",
    "eval_log_reg1=evaluate(predictions_log_reg1_dict,'twitter-test1.txt','log_reg')\n",
    "eval_log_reg2=evaluate(predictions_log_reg2_dict,'twitter-test2.txt','log_reg')\n",
    "eval_log_reg3=evaluate(predictions_log_reg3_dict,'twitter-test3.txt','log_reg')\n",
    "#generate the confusion matrices\n",
    "conf_log_reg1=confusion(predictions_log_reg1_dict,'twitter-test1.txt','log_reg')\n",
    "conf_log_reg2=confusion(predictions_log_reg2_dict,'twitter-test2.txt','log_reg')\n",
    "conf_log_reg3=confusion(predictions_log_reg3_dict,'twitter-test3.txt','log_reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict,Counter\n",
    "word_counter=Counter()\n",
    "for sentences in tweets['twitter-training-data.txt']:\n",
    "    words = list(word_tokenize(sentences))\n",
    "    word_counter.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words=5000\n",
    "words_5000=word_counter.most_common(max_words)\n",
    "word2id=dict()\n",
    "word2id={'unk': 0}\n",
    "for i,word in enumerate(word_counter.keys()):\n",
    "    word2id[word]=i+1\n",
    "id2word = {v: k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the embedding dictionary\n",
    "embeddings_dictionary = dict()\n",
    "glove_name='glove.6B.100d.txt'\n",
    "with open(glove_name,'r', encoding='utf8') as f2:\n",
    "    for line in f2:\n",
    "        word_ = line.split()\n",
    "        word_vector = np.asarray(word_[1:],dtype='float16')\n",
    "        embeddings_dictionary[word_[0]] = word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the embedding matrix\n",
    "import torch\n",
    "embedding_dim=100;\n",
    "embedding_matrix=torch.zeros(len(word_counter)+1, embedding_dim)\n",
    "for word, index in word2id.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = torch.from_numpy(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the labels to numeric\n",
    "train_labels_num=[]\n",
    "for labels in tweetgts['twitter-training-data.txt']:\n",
    "    if labels=='positive':\n",
    "        train_labels_num.append(2)\n",
    "    elif labels=='negative':\n",
    "        train_labels_num.append(0)\n",
    "    else:\n",
    "        train_labels_num.append(1)\n",
    "test1_labels_num=[]\n",
    "test2_labels_num=[]\n",
    "test3_labels_num=[]\n",
    "valid_labels_num=[]\n",
    "for labels in tweetgts['twitter-test1.txt']:\n",
    "    if labels=='positive':\n",
    "        test1_labels_num.append(2)\n",
    "    elif labels=='negative':\n",
    "        test1_labels_num.append(0)\n",
    "    else:\n",
    "        test1_labels_num.append(1)\n",
    "for labels in tweetgts['twitter-test2.txt']:\n",
    "    if labels=='positive':\n",
    "        test2_labels_num.append(2)\n",
    "    elif labels=='negative':\n",
    "        test2_labels_num.append(0)\n",
    "    else:\n",
    "        test2_labels_num.append(1)\n",
    "for labels in tweetgts['twitter-test3.txt']:\n",
    "    if labels=='positive':\n",
    "        test3_labels_num.append(2)\n",
    "    elif labels=='negative':\n",
    "        test3_labels_num.append(0)\n",
    "    else:\n",
    "        test3_labels_num.append(1)\n",
    "for labels in tweetgts['twitter-dev-data.txt']:\n",
    "    if labels=='positive':\n",
    "        valid_labels_num.append(2)\n",
    "    elif labels=='negative':\n",
    "        valid_labels_num.append(0)\n",
    "    else:\n",
    "        valid_labels_num.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the lstm model\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "class TextDataSet(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return text, label\n",
    "        else:\n",
    "            return text\n",
    "        \n",
    "def texts2tensor(texts,word2id,pad_token = 0,max_len = 100):\n",
    "    indexes_list = [[word2id.get(word,0) for word in word_tokenize(text)] for text in texts]\n",
    "    max_len = min(max_len,max([len(indexes) for indexes in indexes_list]))\n",
    "    if max_len > 100:\n",
    "        raise Exception(\"max > 100\")\n",
    "    truncated_indexes = [indexes[:max_len] for indexes in indexes_list]\n",
    "    padded_indexes = [indexes+[0]*(max_len - len(indexes)) for indexes in truncated_indexes]\n",
    "    return torch.LongTensor(padded_indexes)\n",
    "\n",
    "def train_collate(batch_inputs):\n",
    "    texts,labels = zip(*batch_inputs)\n",
    "    input_tensor = texts2tensor(texts,word2id)\n",
    "    return input_tensor,torch.LongTensor(labels)\n",
    "\n",
    "train_dataset = TextDataSet(tweets['twitter-training-data.txt'],train_labels_num)\n",
    "test1_dataset = TextDataSet(tweets['twitter-test1.txt'],test1_labels_num)\n",
    "test2_dataset = TextDataSet(tweets['twitter-test2.txt'],test2_labels_num)\n",
    "test3_dataset = TextDataSet(tweets['twitter-test3.txt'],test3_labels_num)\n",
    "valid_dataset = TextDataSet(tweets['twitter-dev-data.txt'],valid_labels_num)\n",
    "    \n",
    "train_loader = DataLoader(train_dataset,batch_size= 20, shuffle = True,collate_fn=train_collate)\n",
    "test1_loader = DataLoader(test1_dataset,batch_size=20,shuffle=False,collate_fn=train_collate)\n",
    "test2_loader = DataLoader(test2_dataset,batch_size=20,shuffle=False,collate_fn=train_collate)\n",
    "test3_loader = DataLoader(test3_dataset,batch_size=20,shuffle=False,collate_fn=train_collate)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=20,shuffle=False,collate_fn=train_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the lstm model for classification\n",
    "from torch import nn\n",
    "class LstmClassification(nn.Module):\n",
    "    def __init__(self,embedding_matrix):\n",
    "        super(LstmClassification,self).__init__()\n",
    "        self.embedding_matrix=embedding_matrix\n",
    "        #extract the dimensions of the embedding matrix \n",
    "        word_number=self.embedding_matrix.shape[0]\n",
    "        embedding_dim=self.embedding_matrix.shape[1]\n",
    "        #define the size of the hidden layer\n",
    "        self.hidden_size=128;\n",
    "        #define the number of layers\n",
    "        self.num_layers=1;\n",
    "        #define the linear activation function\n",
    "        self.linear  = nn.Linear(in_features=self.hidden_size*1,out_features=3)\n",
    "        #define the lstm model\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_size,num_layers=1,batch_first=True)\n",
    "        #define embedding matrix\n",
    "        self.embedding = nn.Embedding(word_number, embedding_dim)\n",
    "        self.embedding.weight.data.copy_(embedding_matrix)\n",
    "        #do not change the weights in the embedding matrix \n",
    "        self.embedding.weight.requires_grad=False\n",
    "    def forward(self,inputs):\n",
    "        #get outputs\n",
    "        embedded = self.embedding(inputs)\n",
    "        outputs,(hs,cs) = self.lstm(embedded)\n",
    "        return  self.linear(outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated validation loss for epoch 1\n",
      "Current validation loss: 79.2295429110527\n",
      " mean loss: 0.8865138337491675\n",
      "Updated validation loss for epoch 2\n",
      "Current validation loss: 79.02526041865349\n",
      " mean loss: 0.7843568304434736\n",
      "Updated validation loss for epoch 3\n",
      "Current validation loss: 74.70885288715363\n",
      " mean loss: 0.7497183578022828\n",
      "Updated validation loss for epoch 4\n",
      "Current validation loss: 74.06291690468788\n",
      " mean loss: 0.7184780675997126\n",
      "Updated validation loss for epoch 5\n",
      "Current validation loss: 73.95404157042503\n",
      " mean loss: 0.6824796456737933\n",
      "Current validation loss: 74.59383723139763\n",
      " mean loss: 0.6462708931178489\n",
      "Current validation loss: 75.96393448114395\n",
      " mean loss: 0.6068626248627795\n",
      "Current validation loss: 77.87227150797844\n",
      " mean loss: 0.5635580478354971\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "device='cpu'\n",
    "#initialize minimum validation loss\n",
    "min_valid_loss=np.inf\n",
    "#initialize the model\n",
    "model = LstmClassification(embedding_matrix = embedding_matrix).to(device)\n",
    "#define the number of epochs\n",
    "epochs  = 8\n",
    "#define the Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "#start the training\n",
    "for e in range(1,epochs+1):\n",
    "    i1 = 0\n",
    "    total_batch = len(train_loader)\n",
    "    epoch_loss = 0\n",
    "    for tweets_,labels in train_loader:\n",
    "        i1=i1+1\n",
    "        tweets_=tweets_.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #calculate the result\n",
    "        res = model(tweets_)\n",
    "        optimizer.zero_grad()\n",
    "        #calculate the loss\n",
    "        loss = loss_func(res,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #eupdate the epoch loss\n",
    "        epoch_loss += loss.item()\n",
    "    #the model with the lowest validation loss will be used for testing\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for tweets_,labels in valid_loader:\n",
    "        res = model(tweets_)\n",
    "        loss_v =  loss_func(res,labels)\n",
    "        valid_loss += loss_v.item()\n",
    "    #update the mininimum validation loss if current loss is lower \n",
    "    if valid_loss<min_valid_loss:\n",
    "        min_valid_loss=valid_loss\n",
    "        print('Updated validation loss for epoch',e)\n",
    "        torch.save(model.state_dict(),'lstm.pth')\n",
    "    print('Current validation loss:', valid_loss)\n",
    "    print(\" mean loss:\",epoch_loss/total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the best model\n",
    "model.load_state_dict(torch.load('lstm.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels in the tests set\n",
    "model.eval()\n",
    "pred_loaders=[]\n",
    "with torch.no_grad():\n",
    "    for loader in [test1_loader,test2_loader,test3_loader]:\n",
    "        pred_labels = []\n",
    "        for tweets_,labels in loader:\n",
    "            tweets_=tweets_.to('cpu')\n",
    "            labels=labels.to('cpu')\n",
    "            outputs=model(tweets_)\n",
    "            val,pred_label=torch.max(outputs.data,1)\n",
    "            pred_label_list = pred_label.cpu().detach().numpy().tolist()\n",
    "            pred_labels = pred_labels+pred_label_list\n",
    "        pred_loaders.append(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-test1.txt (lstm): 0.623\n",
      "twitter-test2.txt (lstm): 0.621\n",
      "twitter-test3.txt (lstm): 0.587\n"
     ]
    }
   ],
   "source": [
    "#convert labels back to negative, neutral and positive\n",
    "pred_loaders_labels=[]\n",
    "for loaders in pred_loaders:\n",
    "    pred_loader_labels=[]\n",
    "    for pred in loaders:\n",
    "        if pred==0:\n",
    "            pred_loader_labels.append('negative')\n",
    "        elif pred==1:\n",
    "            pred_loader_labels.append('neutral')\n",
    "        elif pred==2:\n",
    "            pred_loader_labels.append('positive')\n",
    "    pred_loaders_labels.append(pred_loader_labels)\n",
    "    \n",
    "predictions_lstm1_dict=dict(zip(tweetids['twitter-test1.txt'],pred_loaders_labels[0]))\n",
    "predictions_lstm2_dict=dict(zip(tweetids['twitter-test2.txt'],pred_loaders_labels[1]))\n",
    "predictions_lstm3_dict=dict(zip(tweetids['twitter-test3.txt'],pred_loaders_labels[2]))\n",
    "\n",
    "#evaluate the lstm model\n",
    "eval_lstm1=evaluate(predictions_lstm1_dict,'twitter-test1.txt','lstm')\n",
    "eval_lstm2=evaluate(predictions_lstm2_dict,'twitter-test2.txt','lstm')\n",
    "eval_lstm3=evaluate(predictions_lstm3_dict,'twitter-test3.txt','lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            positive  negative  neutral\n",
      "positive    0.719     0.040     0.241     \n",
      "negative    0.152     0.714     0.134     \n",
      "neutral     0.215     0.151     0.634     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.751     0.040     0.209     \n",
      "negative    0.108     0.735     0.157     \n",
      "neutral     0.306     0.114     0.580     \n",
      "\n",
      "            positive  negative  neutral\n",
      "positive    0.759     0.053     0.189     \n",
      "negative    0.148     0.579     0.273     \n",
      "neutral     0.282     0.127     0.591     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_lstm1=confusion(predictions_lstm1_dict,'twitter-test1.txt','lstm')\n",
    "confusion_lstm2=confusion(predictions_lstm2_dict,'twitter-test2.txt','lstm')\n",
    "confusion_lstm3=confusion(predictions_lstm3_dict,'twitter-test3.txt','lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
